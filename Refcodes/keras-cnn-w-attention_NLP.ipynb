{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["from csv import DictReader\n","from random import Random\n","from collections import Counter\n","import numpy as np\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-input":true,"_uuid":"f2cd49442708186b9a201f1df0de45bc461c0acc","trusted":true},"outputs":[],"source":["RANDOM = Random(42)"]},{"cell_type":"markdown","metadata":{"_uuid":"6375e90151f1fa6825c0fffba46fd52431b9196b"},"source":["## Load Data"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["def load_samples(path):\n","    with open(path) as f:\n","        samples = list(DictReader(f))\n","        for sample in samples:\n","            sample['target'] = int(sample.get('target', -1))\n","        return samples"]},{"cell_type":"code","execution_count":4,"metadata":{"_kg_hide-input":true,"_uuid":"c3c4db7c62ab4796c171f7174f2e6345b7d0ce3f","trusted":true},"outputs":[],"source":["def train_val_split(samples, split=0.2):\n","    RANDOM.shuffle(samples)\n","    n_val = int(len(samples) * split)\n","    return samples[:-n_val], samples[-n_val:]"]},{"cell_type":"code","execution_count":5,"metadata":{"_kg_hide-input":true,"_uuid":"9d8941a4f539548786ac55a0405c98142d43bf92","trusted":true},"outputs":[],"source":["def undersample_majority(samples, factor=2.0):\n","    classes, counts = np.unique([sample['target'] for sample in samples], return_counts=True)\n","    minority_class_count = counts.min()\n","    undersampled = []\n","    for class_ in classes:\n","        class_samples = [sample for sample in samples if sample['target'] == class_]\n","        RANDOM.shuffle(class_samples)\n","        undersampled.extend(class_samples[:int(minority_class_count * factor)])\n","    return undersampled"]},{"cell_type":"code","execution_count":6,"metadata":{"_uuid":"7aa1950951427c5084166755d6c7a6c3e374971f","trusted":true},"outputs":[],"source":["samples = load_samples('/Users/suhancho/data/kaggle/quora_insincere/train.csv')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import pandas as pd\n","rawdata = pd.read_table('/Users/suhancho/data/kaggle/quora_insincere/train.csv',sep=',')"]},{"cell_type":"code","execution_count":9,"metadata":{"_uuid":"6520f247d43cb0be94897b5ed13daa1ca81ea552","trusted":true},"outputs":[],"source":["train_samples, val_samples = train_val_split(samples)"]},{"cell_type":"markdown","metadata":{"_uuid":"b51eca3370a9f1e2e735f3892781d55923402212"},"source":["## Sampling"]},{"cell_type":"code","execution_count":10,"metadata":{"_kg_hide-input":true,"_uuid":"a81ab7b8d014d7d91af892c871309a6732fd1897","trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.title('Target Distribution')\n","plt.hist([sample['target'] for sample in train_samples])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_uuid":"0a91472b0fba9ee2cfa7082d9fbc54da16cee05f"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":11,"metadata":{"_kg_hide-input":true,"_uuid":"759aba1d10c5942009ba1540b71604be7bdcbdcb","trusted":true},"outputs":[],"source":["def build_vocabulary(samples, vocab_min_freq=100):\n","    counts = Counter(ch for sample in samples for ch in sample['question_text'])\n","    chars = sorted(ch for ch, count in counts.items() if count >= vocab_min_freq)\n","    return {char: i for i, char in enumerate(chars)}"]},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"cea3ed30248f4fa394441ca98296c1bb1de485ad","trusted":true},"outputs":[],"source":["vocabulary = build_vocabulary(train_samples)\n","# print(len(vocabulary))\n","# vocabulary"]},{"cell_type":"code","execution_count":13,"metadata":{"_kg_hide-input":true,"_uuid":"0399fafa54b3210aa5de3cc776943c2135776605","trusted":true},"outputs":[],"source":["def transform(sample, vocabulary):\n","    sample['encoded_text'] = [vocabulary[ch] for ch in sample['question_text'] if ch in vocabulary]\n","    return sample"]},{"cell_type":"code","execution_count":12,"metadata":{"_uuid":"3112df9441d7d951e0e759fb1fcca1d09d93048a","trusted":true},"outputs":[],"source":["train_samples = [transform(sample, vocabulary) for sample in train_samples]\n","val_samples = [transform(sample, vocabulary) for sample in val_samples]"]},{"cell_type":"markdown","metadata":{"_uuid":"0ccbddf1488f16c8842ff260969dd540ab7397a8"},"source":["## Modeling"]},{"cell_type":"code","execution_count":14,"metadata":{"_kg_hide-input":false,"_uuid":"77b407777c42a5df4ab0b175e25751f289f7f655","trusted":true},"outputs":[],"source":["import keras\n","from keras import backend as K\n","from keras import initializers, regularizers, constraints\n","# from keras.engine import Layer\n","# from tensorflow.keras.layers import Layer\n","def dot_product(x, kernel):\n","    \"\"\"\n","    Wrapper for dot product operation, in order to be compatible with both\n","    Theano and Tensorflow\n","    Args:\n","        x (): input\n","        kernel (): weights\n","    Returns:\n","    \"\"\"\n","    if K.backend() == 'tensorflow':\n","        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n","    else:\n","        return K.dot(x, kernel)\n","# from keras.layers import InputLayer, Input\n","\n","class AttentionWithContext(keras.layers.Layer):\n","    \"\"\"\n","    Attention operation, with a context/query vector, for temporal data.\n","    Supports Masking.\n","    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n","    \"Hierarchical Attention Networks for Document Classification\"\n","    by using a context vector to assist the attention\n","    # Input shape\n","        3D tensor with shape: `(samples, steps, features)`.\n","    # Output shape\n","        2D tensor with shape: `(samples, features)`.\n","\n","    How to use:\n","    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n","    The dimensions are inferred based on the output shape of the RNN.\n","\n","    Note: The layer has been tested with Keras 2.0.6\n","\n","    Example:\n","        model.add(LSTM(64, return_sequences=True))\n","        model.add(AttentionWithContext())\n","        # next add a Dense layer (for classification/regression) or whatever...\n","    \"\"\"\n","\n","    def __init__(self,\n","                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, u_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","\n","        self.supports_masking = True\n","        self.init = initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = regularizers.get(W_regularizer)\n","        self.u_regularizer = regularizers.get(u_regularizer)\n","        self.b_regularizer = regularizers.get(b_regularizer)\n","\n","        self.W_constraint = constraints.get(W_constraint)\n","        self.u_constraint = constraints.get(u_constraint)\n","        self.b_constraint = constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        super(AttentionWithContext, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight(shape = (input_shape[-1], input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        if self.bias:\n","            self.b = self.add_weight(shape = (input_shape[-1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","\n","        self.u = self.add_weight(shape = (input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_u'.format(self.name),\n","                                 regularizer=self.u_regularizer,\n","                                 constraint=self.u_constraint)\n","\n","        super(AttentionWithContext, self).build(input_shape)\n","\n","    def compute_mask(self, input, input_mask=None):\n","        # do not pass the mask to the next layers\n","        return None\n","\n","    def call(self, x, mask=None):\n","        uit = dot_product(x, self.W)\n","\n","        if self.bias:\n","            uit += self.b\n","\n","        uit = K.tanh(uit)\n","        ait = dot_product(uit, self.u)\n","\n","        a = K.exp(ait)\n","\n","        # apply mask after the exp. will be re-normalized next\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            a *= K.cast(mask, K.floatx())\n","\n","        # in some cases especially in the early stages of training the sum may be almost zero\n","        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n","        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        return K.sum(weighted_input, axis=1)\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0], input_shape[-1]\n"]},{"cell_type":"code","execution_count":15,"metadata":{"_uuid":"b00234b1283b37886bb9e1f5307ed01a3a79ecb2","trusted":true},"outputs":[],"source":["from keras import models, Model\n","from keras.layers import Input, Embedding, Conv1D, Add, Dense, SpatialDropout1D\n","\n","def _conv_block(x, filters, kernel_size):\n","    conv = Conv1D(filters, kernel_size, activation='relu', padding='same')(x)\n","    conv = Conv1D(filters, kernel_size, activation='relu', padding='same')(conv)\n","    return conv\n","\n","\n","def _resblock(x, filters, kernel_size):\n","    conv = _conv_block(x, filters, kernel_size)\n","    projection = Conv1D(filters, 1, padding='same')(x)\n","    return Add()([conv, projection])\n","\n","\n","def troll_hunter(vocab_size,\n","                 char_embedding_size,\n","                 base_filters,\n","                 doc_embedding_size,\n","                 dropout):\n","    text = Input(shape=(None,))\n","    embedding = Embedding(vocab_size, char_embedding_size)(text)\n","\n","    conv_1 = _resblock(embedding, base_filters, 3)\n","    conv_1 = SpatialDropout1D(dropout)(conv_1)\n","    conv_2 = _resblock(conv_1, base_filters * 2, 3)\n","    conv_2 = SpatialDropout1D(dropout)(conv_2)\n","    conv_3 = _resblock(conv_2, base_filters * 4, 3)\n","    conv_3 = SpatialDropout1D(dropout)(conv_3)\n","    conv_4 = _resblock(conv_3, base_filters * 8, 3)\n","    conv_4 = SpatialDropout1D(dropout)(conv_4)\n","\n","    attention = AttentionWithContext()(conv_4)\n","\n","    fc_1 = Dense(doc_embedding_size, activation='relu')(attention)\n","    fc_2 = Dense(doc_embedding_size, activation='relu')(fc_1)\n","    prediction = Dense(1, activation='sigmoid')(fc_2)\n","\n","    model = Model(text, prediction)\n","    model.compile('adam', 'binary_crossentropy', metrics=['acc'])\n","    return model"]},{"cell_type":"markdown","metadata":{"_uuid":"9c48deb6eb418c4e0fefb4321d8ec66d83633d72"},"source":["## Training Support"]},{"cell_type":"code","execution_count":16,"metadata":{"_uuid":"c80edd9ecc0469f7ba9b0b8e26f5d2c894f2e2ed","trusted":true},"outputs":[],"source":["from math import ceil\n","\n","class BatchProvider:\n","    def __init__(self, samples, batch_size, shuffle=False, run_forever=False):\n","        self._samples = samples\n","        self._batch_size = batch_size\n","        self._shuffle = shuffle\n","        self._run_forever = run_forever\n","\n","    def generate_batches(self):\n","        batch = []\n","        indices = list(range(len(self._samples)))\n","        while True:\n","            if self._shuffle:\n","                RANDOM.shuffle(indices)\n","            for i in indices:\n","                batch.append(self.get_item(i))\n","                if len(batch) == self._batch_size:\n","                    yield self.transform_batch(batch)\n","                    batch = []\n","            if not self._run_forever:\n","                break\n","        if batch:\n","            yield self.transform_batch(batch)\n","\n","    def __len__(self):\n","        return int(ceil(len(self._samples) / self._batch_size))\n","\n","    def get_item(self, idx):\n","        sample = self._samples[idx]\n","        return sample['encoded_text'], sample['target']\n","\n","    def transform_batch(self, items):\n","        texts, targets = zip(*items)\n","        max_length = max(len(text) for text in texts)\n","        text_batch = np.zeros((len(texts), max_length))\n","        for i, text in enumerate(texts):\n","            text_batch[i, :len(text)] = text\n","        target_batch = np.array(targets)\n","        return text_batch, target_batch"]},{"cell_type":"markdown","metadata":{"_uuid":"965761540885c8c9f94fbd18296ee2415edf8f3c"},"source":["## Training"]},{"cell_type":"code","execution_count":17,"metadata":{"_uuid":"e4dfbf9e3e87cad230b8f72719ce71e1e94303fb","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/suhancho/miniforge3/envs/keras/lib/python3.8/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, None)]       0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, None, 16)     1920        ['input_1[0][0]']                \n","                                                                                                  \n"," conv1d (Conv1D)                (None, None, 32)     1568        ['embedding[0][0]']              \n","                                                                                                  \n"," conv1d_1 (Conv1D)              (None, None, 32)     3104        ['conv1d[0][0]']                 \n","                                                                                                  \n"," conv1d_2 (Conv1D)              (None, None, 32)     544         ['embedding[0][0]']              \n","                                                                                                  \n"," add (Add)                      (None, None, 32)     0           ['conv1d_1[0][0]',               \n","                                                                  'conv1d_2[0][0]']               \n","                                                                                                  \n"," spatial_dropout1d (SpatialDrop  (None, None, 32)    0           ['add[0][0]']                    \n"," out1D)                                                                                           \n","                                                                                                  \n"," conv1d_3 (Conv1D)              (None, None, 64)     6208        ['spatial_dropout1d[0][0]']      \n","                                                                                                  \n"," conv1d_4 (Conv1D)              (None, None, 64)     12352       ['conv1d_3[0][0]']               \n","                                                                                                  \n"," conv1d_5 (Conv1D)              (None, None, 64)     2112        ['spatial_dropout1d[0][0]']      \n","                                                                                                  \n"," add_1 (Add)                    (None, None, 64)     0           ['conv1d_4[0][0]',               \n","                                                                  'conv1d_5[0][0]']               \n","                                                                                                  \n"," spatial_dropout1d_1 (SpatialDr  (None, None, 64)    0           ['add_1[0][0]']                  \n"," opout1D)                                                                                         \n","                                                                                                  \n"," conv1d_6 (Conv1D)              (None, None, 128)    24704       ['spatial_dropout1d_1[0][0]']    \n","                                                                                                  \n"," conv1d_7 (Conv1D)              (None, None, 128)    49280       ['conv1d_6[0][0]']               \n","                                                                                                  \n"," conv1d_8 (Conv1D)              (None, None, 128)    8320        ['spatial_dropout1d_1[0][0]']    \n","                                                                                                  \n"," add_2 (Add)                    (None, None, 128)    0           ['conv1d_7[0][0]',               \n","                                                                  'conv1d_8[0][0]']               \n","                                                                                                  \n"," spatial_dropout1d_2 (SpatialDr  (None, None, 128)   0           ['add_2[0][0]']                  \n"," opout1D)                                                                                         \n","                                                                                                  \n"," conv1d_9 (Conv1D)              (None, None, 256)    98560       ['spatial_dropout1d_2[0][0]']    \n","                                                                                                  \n"," conv1d_10 (Conv1D)             (None, None, 256)    196864      ['conv1d_9[0][0]']               \n","                                                                                                  \n"," conv1d_11 (Conv1D)             (None, None, 256)    33024       ['spatial_dropout1d_2[0][0]']    \n","                                                                                                  \n"," add_3 (Add)                    (None, None, 256)    0           ['conv1d_10[0][0]',              \n","                                                                  'conv1d_11[0][0]']              \n","                                                                                                  \n"," spatial_dropout1d_3 (SpatialDr  (None, None, 256)   0           ['add_3[0][0]']                  \n"," opout1D)                                                                                         \n","                                                                                                  \n"," attention_with_context (Attent  (None, 256)         66048       ['spatial_dropout1d_3[0][0]']    \n"," ionWithContext)                                                                                  \n","                                                                                                  \n"," dense (Dense)                  (None, 300)          77100       ['attention_with_context[0][0]'] \n","                                                                                                  \n"," dense_1 (Dense)                (None, 300)          90300       ['dense[0][0]']                  \n","                                                                                                  \n"," dense_2 (Dense)                (None, 1)            301         ['dense_1[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 672,309\n","Trainable params: 672,309\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["model = troll_hunter(\n","    vocab_size=len(vocabulary),\n","    char_embedding_size=16,\n","    base_filters=32,\n","    doc_embedding_size=300,\n","    dropout=0.1\n",")\n","model.summary()"]},{"cell_type":"code","execution_count":18,"metadata":{"_uuid":"1edff22ca083ce90322122f6766efccb3c51e397","trusted":true},"outputs":[],"source":["train_batch_provider = BatchProvider(train_samples, batch_size=64, shuffle=True, run_forever=True)\n","train_batches = train_batch_provider.generate_batches()"]},{"cell_type":"code","execution_count":19,"metadata":{"_uuid":"012e9b9f66fb77eedb99ecf64370658eba15d41e","trusted":true},"outputs":[],"source":["val_batch_provider = BatchProvider(val_samples, batch_size=64, shuffle=False, run_forever=True)\n","val_batches = val_batch_provider.generate_batches()"]},{"cell_type":"code","execution_count":20,"metadata":{"_uuid":"4441866a3c94e2ca359fd9b87dfac1ea82e46e18","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-20-2dc1f2db5302>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","  155/16327 [..............................] - ETA: 1:20:28 - loss: 0.2333 - acc: 0.9370"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint, EarlyStopping\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_batch_provider\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_batch_provider\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweights.hdf5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_acc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/keras/lib/python3.8/site-packages/keras/engine/training.py:2507\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2495\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2496\u001b[0m \n\u001b[1;32m   2497\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2499\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2500\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2501\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2502\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2503\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2504\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2505\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2506\u001b[0m )\n\u001b[0;32m-> 2507\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   2508\u001b[0m     generator,\n\u001b[1;32m   2509\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   2510\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   2511\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2512\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   2513\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   2514\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   2515\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   2516\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   2517\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2518\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2519\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2520\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   2521\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   2522\u001b[0m )\n","File \u001b[0;32m~/miniforge3/envs/keras/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/miniforge3/envs/keras/lib/python3.8/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/miniforge3/envs/keras/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/miniforge3/envs/keras/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/miniforge3/envs/keras/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m~/miniforge3/envs/keras/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/miniforge3/envs/keras/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/miniforge3/envs/keras/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m~/miniforge3/envs/keras/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","model.fit_generator(\n","        generator=train_batches,\n","        steps_per_epoch=len(train_batch_provider),\n","        epochs=5,\n","        validation_data=val_batches,\n","        validation_steps=len(val_batch_provider),\n","        callbacks=[\n","            ModelCheckpoint('weights.hdf5', monitor='val_acc', save_best_only=True),\n","        ]\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"7a900ae6d2f4acbb51cf6d575292a871b481b8eb","trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."]}],"source":["model.load_weights('weights.hdf5')"]},{"cell_type":"markdown","metadata":{"_uuid":"ad3b029bee337c9e6b24d333f231019d610888be"},"source":["## Calibration"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f80b3326275604524a6279aec1b0e30e81812c1c","trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."]}],"source":["from sklearn.metrics import precision_recall_curve\n","\n","val_batch_provider = BatchProvider(val_samples, batch_size=64, shuffle=False, run_forever=False)\n","val_predictions = model.predict_generator(val_batch_provider.generate_batches(), steps=len(val_batch_provider))\n","val_targets = np.array([sample['target'] for sample in val_samples])\n","\n","precisions, recalls, thresholds = precision_recall_curve(val_targets, val_predictions[:, 0])\n","precisions = precisions[:-1]\n","recalls = recalls[:-1]\n","f1_scores = 2 * ((precisions * recalls) / (precisions + recalls))\n","threshold = thresholds[f1_scores.argmax()]"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"d434acfed7a51f361983610f0fca33f6b0f2cb27","trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."]}],"source":["print('f1: %f, threshold: %f' % (f1_scores.max(), threshold))"]},{"cell_type":"markdown","metadata":{"_uuid":"5bcb2fbc865437cb6cc563d21e67a6e95523ccda"},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"59d291977e9cfc894afd4daa7c499d2d36dba914","trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."]}],"source":["from keras.utils import GeneratorEnqueuer\n","import csv"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e5f67585f0930085a0a450aafe5046cc391bbec5","trusted":true},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mnotebook controller is DISPOSED. \n","자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."]}],"source":["test_samples = load_samples('../input/test.csv')\n","test_samples = [transform(sample, vocabulary) for sample in test_samples]\n","sample_ids = (sample['qid'] for sample in test_samples)\n","\n","test_batch_provider = BatchProvider(test_samples, batch_size=64, shuffle=False, run_forever=False)\n","enqueuer = GeneratorEnqueuer(test_batch_provider.generate_batches())\n","enqueuer.start()\n","test_batches = enqueuer.get()\n","\n","with open('submission.csv', 'w') as submission_file:\n","    submission_writer = csv.writer(submission_file)\n","    submission_writer.writerow(['qid', 'prediction'])\n","    for batch, _ in test_batches:\n","        predictions = model.predict_on_batch(batch)\n","        for prediction in predictions:\n","            sample_id = next(sample_ids)\n","            submission_writer.writerow([sample_id, 1 if prediction[0] >= threshold else 0])"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.6 ('keras')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"ea3476042c22507d4a4a83ae58c770fc528ff15454871552e09ef37283ce2491"}}},"nbformat":4,"nbformat_minor":1}

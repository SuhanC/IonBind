{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preproc_utils import *\n",
    "from Get_PSSM import *\n",
    "from Get_dataset import *\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score,f1_score\n",
    "\n",
    "chebi = pd.read_table('/Users/suhancho/data/Uniprot_metalbinding_challenge/POS_TRAIN_FULL.tsv')\n",
    "inpath = '/Users/suhancho/data/Uniprot_metalbinding_challenge/chebi/'\n",
    "bind_tsv_list = [inpath + f for f in os.listdir(inpath)]\n",
    "pssm_path = '/Users/suhancho/data/Uniprot_metalbinding_challenge/PSSM/'\n",
    "pssm_files = [pssm_path+f for f in os.listdir(pssm_path)]\n",
    "bindlist = pd.concat([pd.read_table(f) for f in bind_tsv_list])\n",
    "low_labels = [l.replace(' ','') for l in bindlist.Name.value_counts().index[bindlist.Name.value_counts()<1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_window(num_inspections,bs_idx):\n",
    "    train_dat=[]\n",
    "    for i,pssm in tqdm(enumerate(pssm_files[0:num_inspections])):\n",
    "        ion_file =bind_tsv_list[bs_idx] # bs_idx : 0~29\n",
    "        ion_name = ion_file.split('/')[-1].split('.')[0]\n",
    "        bs = get_binding_site(ion_file,pssm.split('/')[-1].split('.')[0])\n",
    "        try : \n",
    "            if len(bs)!=0:\n",
    "                # gt,fs = get_dataset(get_processed_pssm(pssm),bs)\n",
    "                gt,fs = get_dataset_padded(get_processed_pssm(pssm),bs)\n",
    "                # print(\"Number of positive windows:\"+str(len(gt))+'\\n'+\n",
    "                #       \"Number of negative windows:\"+str(len(fs)))\n",
    "                for g in gt : \n",
    "                    train_dat.append([g.values.tolist(),1])\n",
    "                for f in fs : \n",
    "                    train_dat.append([f.values.tolist(),0])\n",
    "        except:\n",
    "            print(pssm)\n",
    "\n",
    "    return(train_dat,ion_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(windowdata):\n",
    "    train_X = [dat[0] for dat in windowdata]\n",
    "    train_Y = [dat[1] for dat in windowdata]\n",
    "    print('Size of dataset : '+str(len(train_X)))\n",
    "    return(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def check_windowdata(traindata):\n",
    "    sns.histplot([len(t) for t in traindata])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_traindata(Xdata,Ydata):\n",
    "    train_X_filtered = [Xdata[i] for i in range(len(Xdata)) if len(Xdata[i])==9]\n",
    "    train_Y_filtered = [Ydata[i] for i in range(len(Xdata)) if len(Xdata[i])==9]\n",
    "    return(train_X_filtered,train_Y_filtered)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def flatten_Xdata(filtered_X):\n",
    "    flatten_trainX = [list(chain.from_iterable(lst)) for lst in filtered_X]\n",
    "    return(flatten_trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MLmetrics(testset_y,testset_X,classifier,ion_name):\n",
    "    auc = roc_auc_score(testset_y,list(classifier.predict(testset_X)))\n",
    "    acc = accuracy_score(testset_y,list(classifier.predict(testset_X)))\n",
    "    recall = recall_score(testset_y,list(classifier.predict(testset_X)))\n",
    "    f1 = f1_score(testset_y,list(classifier.predict(testset_X)))\n",
    "    prec = precision_score(testset_y,list(classifier.predict(testset_X)))\n",
    "    print('ION = '+ion_name)\n",
    "    print('\\nAUC = '+str(round(auc,2)))\n",
    "    print('\\nAccuracy = '+str(round(acc,2)))\n",
    "    print('\\nRecall = '+str(round(recall,2)))\n",
    "    print('\\nF1 = '+str(round(f1,2)))\n",
    "    print('Precision = '+str(round(prec,2)))\n",
    "    return(auc,acc,recall,f1,prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes(traindata,fold):\n",
    "    label1 = [traindata[i] for i in range(len(traindata)) if traindata[i][1]==1]\n",
    "    label0 = [traindata[i] for i in range(len(traindata)) if traindata[i][1]==0]\n",
    "    balanced0 = random.sample(label0,len(label1)*fold)\n",
    "    return(balanced0+label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90000it [01:40, 895.90it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 248\n",
      "ION = Cu(+)\n",
      "\n",
      "AUC = 0.93\n",
      "\n",
      "Accuracy = 0.96\n",
      "\n",
      "Recall = 0.88\n",
      "\n",
      "F1 = 0.92\n",
      "Precision = 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90000it [01:00, 1490.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 104\n",
      "ION = Hg(2+)\n",
      "\n",
      "AUC = 0.91\n",
      "\n",
      "Accuracy = 0.95\n",
      "\n",
      "Recall = 0.82\n",
      "\n",
      "F1 = 0.9\n",
      "Precision = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90000it [01:13, 1228.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 208\n",
      "ION = [8Fe-7S]cluster\n",
      "\n",
      "AUC = 0.99\n",
      "\n",
      "Accuracy = 0.99\n",
      "\n",
      "Recall = 1.0\n",
      "\n",
      "F1 = 0.98\n",
      "Precision = 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90000it [00:52, 1720.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 16\n",
      "ION = [8Fe-9S-C-homocitryl]cluster\n",
      "\n",
      "AUC = 0.5\n",
      "\n",
      "Accuracy = 0.71\n",
      "\n",
      "Recall = 0.0\n",
      "\n",
      "F1 = 0.0\n",
      "Precision = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90000it [01:23, 1072.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 284\n",
      "ION = Co(2+)\n",
      "\n",
      "AUC = 0.85\n",
      "\n",
      "Accuracy = 0.88\n",
      "\n",
      "Recall = 0.79\n",
      "\n",
      "F1 = 0.76\n",
      "Precision = 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:07, 646.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 64\n",
      "ION = iron-sulfurcluster\n",
      "\n",
      "AUC = 0.86\n",
      "\n",
      "Accuracy = 0.92\n",
      "\n",
      "Recall = 0.71\n",
      "\n",
      "F1 = 0.83\n",
      "Precision = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [03:16, 25.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 2520\n",
      "ION = [4Fe-4S]cluster\n",
      "\n",
      "AUC = 0.99\n",
      "\n",
      "Accuracy = 0.99\n",
      "\n",
      "Recall = 0.98\n",
      "\n",
      "F1 = 0.97\n",
      "Precision = 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90000it [01:33, 962.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 128\n",
      "ION = Cd(2+)\n",
      "\n",
      "AUC = 0.74\n",
      "\n",
      "Accuracy = 0.85\n",
      "\n",
      "Recall = 0.54\n",
      "\n",
      "F1 = 0.64\n",
      "Precision = 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [01:13, 68.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 988\n",
      "ION = adivalentmetalcation\n",
      "\n",
      "AUC = 0.88\n",
      "\n",
      "Accuracy = 0.92\n",
      "\n",
      "Recall = 0.8\n",
      "\n",
      "F1 = 0.83\n",
      "Precision = 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:27, 180.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 248\n",
      "ION = Cucation\n",
      "\n",
      "AUC = 0.83\n",
      "\n",
      "Accuracy = 0.9\n",
      "\n",
      "Recall = 0.71\n",
      "\n",
      "F1 = 0.77\n",
      "Precision = 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90000it [01:03, 1420.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 32\n",
      "ION = [Ni-4Fe-5S]cluster\n",
      "\n",
      "AUC = 0.67\n",
      "\n",
      "Accuracy = 0.85\n",
      "\n",
      "Recall = 0.33\n",
      "\n",
      "F1 = 0.5\n",
      "Precision = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [09:27,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 6080\n",
      "ION = Zn(2+)\n",
      "\n",
      "AUC = 0.94\n",
      "\n",
      "Accuracy = 0.96\n",
      "\n",
      "Recall = 0.92\n",
      "\n",
      "F1 = 0.91\n",
      "Precision = 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90000it [00:52, 1705.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 16\n",
      "ION = Co(3+)\n",
      "\n",
      "AUC = 0.5\n",
      "\n",
      "Accuracy = 0.71\n",
      "\n",
      "Recall = 0.0\n",
      "\n",
      "F1 = 0.0\n",
      "Precision = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90000it [01:27, 1028.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 64\n",
      "ION = [Ni-4Fe-4S]cluster\n",
      "\n",
      "AUC = 0.98\n",
      "\n",
      "Accuracy = 0.96\n",
      "\n",
      "Recall = 1.0\n",
      "\n",
      "F1 = 0.92\n",
      "Precision = 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [01:04, 77.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset : 908\n",
      "ION = Fecation\n",
      "\n",
      "AUC = 0.93\n",
      "\n",
      "Accuracy = 0.95\n",
      "\n",
      "Recall = 0.9\n",
      "\n",
      "F1 = 0.9\n",
      "Precision = 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23842it [00:41, 614.85it/s]"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "for i,b in enumerate(bind_tsv_list):\n",
    "    b_tmp = open(b,'r').readlines()\n",
    "\n",
    "    if len(b_tmp)<1000:\n",
    "        iter = 90000\n",
    "    else : \n",
    "        iter = 5000\n",
    "\n",
    "    train_dat,ion = calculate_window(iter,i)\n",
    "    train_dat = balance_classes(train_dat,3)\n",
    "    train_X,train_Y = preproc_data(train_dat)\n",
    "    # check_windowdata(train_X)\n",
    "    train_X,train_Y = filter_traindata(train_X,train_Y)\n",
    "    flatten_trainX = flatten_Xdata(train_X)\n",
    "    trainX, testX, trainy, testy = train_test_split(flatten_trainX,train_Y,test_size=0.4,shuffle = True,stratify=train_Y)\n",
    "\n",
    "    X = trainX ; y = trainy\n",
    "\n",
    "    pipe_svc = make_pipeline(StandardScaler(),SVC(random_state=9510))\n",
    "\n",
    "    param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "    param_grid = [{'svc__C': param_range, \n",
    "                'svc__kernel': ['linear']},\n",
    "                {'svc__C': param_range, \n",
    "                'svc__gamma': param_range, \n",
    "                'svc__kernel': ['rbf']}]\n",
    "\n",
    "    gs = GridSearchCV(estimator=pipe_svc, \n",
    "                    param_grid=param_grid, \n",
    "                    scoring='accuracy', \n",
    "                    cv=3,\n",
    "                    n_jobs=-1)\n",
    "    gs = gs.fit(X, y)\n",
    "    auc,acc,f1,recall,prec = get_MLmetrics(testy,testX,gs,ion)\n",
    "    result.append([auc,acc,f1,recall,prec,ion])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('sklearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ca674affdede15e4a6394b48f5e33f7f932c70ec65fc4d25734b56c029e94fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(inplanes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    r\"\"\"\n",
    "    3x3 convolution with padding\n",
    "    - inplanes: in_channels\n",
    "    - out_channels: out_channels\n",
    "    - bias=False: BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(inplanes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(inplanes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(inplanes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,dilation=1, norm_layer=None):\n",
    "        r\"\"\"\n",
    "         - inplanes: input channel size\n",
    "         - planes: output channel size\n",
    "         - groups, base_width: ResNext나 Wide ResNet의 경우 사용\n",
    "        \"\"\"\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        # Basic Block의 구조\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)  # conv1에서 downsample\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # short connection\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            \n",
    "        # identity mapping시 identity mapping후 ReLU를 적용합니다.\n",
    "        # 그 이유는, ReLU를 통과하면 양의 값만 남기 때문에 Residual의 의미가 제대로 유지되지 않기 때문입니다.\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=30, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        # default values\n",
    "        self.inplanes = 1 # input feature map\n",
    "        self.dilation = 1\n",
    "        # stride를 dilation으로 대체할지 선택\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        \n",
    "        r\"\"\"\n",
    "        - 처음 입력에 적용되는 self.conv1과 self.bn1, self.relu는 모든 ResNet에서 동일 \n",
    "        - 3: 입력으로 RGB 이미지를 사용하기 때문에 convolution layer에 들어오는 input의 channel 수는 3\n",
    "        \"\"\"\n",
    "        # self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=4, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        r\"\"\"\n",
    "        - 아래부터 block 형태와 갯수가 ResNet층마다 변화\n",
    "        - self.layer1 ~ 4: 필터의 개수는 각 block들을 거치면서 증가(64->128->256->512)\n",
    "        - self.avgpool: 모든 block을 거친 후에는 Adaptive AvgPool2d를 적용하여 (n, 512, 1, 1)의 텐서로\n",
    "        - self.fc: 이후 fc layer를 연결\n",
    "        \"\"\"\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, # 여기서부터 downsampling적용\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.layer5 = self._make_layer(block, 1024, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.layer6 = self._make_layer(block, 2048, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.drop = nn.Dropout2d()\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        r\"\"\"\n",
    "        convolution layer 생성 함수\n",
    "        - block: block종류 지정\n",
    "        - planes: feature map size (input shape)\n",
    "        - blocks: layers[0]와 같이, 해당 블록이 몇개 생성돼야하는지, 블록의 갯수 (layer 반복해서 쌓는 개수)\n",
    "        - stride와 dilate은 고정\n",
    "        \"\"\"\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        \n",
    "        # the number of filters is doubled: self.inplanes와 planes 사이즈를 맞춰주기 위한 projection shortcut\n",
    "        # the feature map size is halved: stride=2로 downsampling\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        # 블록 내 시작 layer, downsampling 필요\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion # inplanes 업데이트\n",
    "        # 동일 블록 반복\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "\n",
    "        aa_len = x.shape[2]\n",
    "        lazy1 = nn.LazyLinear(30)\n",
    "        lazy2 = nn.LazyLinear(aa_len)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = F.avg_pool2d(x,2)\n",
    "        x = torch.squeeze(x,-1)\n",
    "        x = lazy1(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = lazy2(x)\n",
    "        x = self.drop(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSSMDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,pssm_in,label_in):\n",
    "        self.pssm_lst = sorted(os.listdir(pssm_in))\n",
    "        self.pssm_files = [pssm_in+f for f in self.pssm_lst]\n",
    "        self.label_files = [label_in+f.split('.')[0]+'.label.txt' for f in self.pssm_lst]\n",
    "    def __len__(self):\n",
    "        return len(self.label_files)\n",
    "    def __getitem__(self, idx):\n",
    "        self.pssm_tensor = torch.tensor(pd.read_table(self.pssm_files[idx],index_col=0).astype(float).values) # Processed PSSM\n",
    "        # self.pssm_tensor = torch.tensor(pd.read_table(self.pssm_files[idx],index_col=0).iloc[:,0:20].astype(float).values) # Raw PSSM\n",
    "        self.label_tensor = torch.tensor(list(map(int,open(self.label_files[idx],'r').readlines()[0].split(','))))\n",
    "        return self.pssm_tensor, self.label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    len_data = [len(item[0]) for item in batch]\n",
    "\n",
    "    target = [item[1] for item in batch]\n",
    "    dim_data = [d.size()[0] for d in data]\n",
    "    max_seqlen = max(dim_data)\n",
    "    data_transformed = [torch.nn.functional.normalize(F.pad(d.T,(0,int(max_seqlen - d.size()[0])),'constant',0.0)).T \n",
    "                        if d.size()[0]!=max_seqlen else d for d in data]\n",
    "    target_transformed = [F.pad(d,(0,int(max_seqlen - d.size()[0])),'constant',0.0) \n",
    "                          if d.size()[0]!=max_seqlen else d for d in target]\n",
    "    target_onehot = [torch.nn.functional.one_hot(t,num_classes = 30) for t in target_transformed]\n",
    "    \n",
    "    data_transformed = torch.nn.utils.rnn.pad_sequence(data_transformed,batch_first=True)\n",
    "    target_result = torch.nn.utils.rnn.pad_sequence(target_onehot,batch_first=True)\n",
    "    return [data_transformed, target_result,len_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "pssminpath = '/Users/suhancho/data/Uniprot_metalbinding_challenge/processed_pssm/'\n",
    "labelinpath = '/Users/suhancho/data/Uniprot_metalbinding_challenge/processed_label/'\n",
    "\n",
    "train_ds = PSSMDataset(pssminpath,labelinpath)\n",
    "train_dl = DataLoader(train_ds,batch_size = batch_size,shuffle = True,collate_fn=my_collate)\n",
    "\n",
    "model = ResNet(BasicBlock,[2,2,2,2])\n",
    "\n",
    "from torch import optim\n",
    "device = 'cpu'\n",
    "\n",
    "lr = 1e-05\n",
    "num_epochs = 5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "# loss_function = nn.MSELoss()\n",
    "params = {\n",
    "    'num_epochs':num_epochs,\n",
    "    'optimizer':optimizer,\n",
    "    'loss_function':loss_function,\n",
    "    'device':device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pseudo-lab.github.io/pytorch-guide/docs/ch04-1.html\n",
    "soft = nn.Softmax(dim=1)\n",
    "\n",
    "def train(model, params):\n",
    "    loss_function=params[\"loss_function\"]\n",
    "    device=params[\"device\"]\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for epoch in range(0, num_epochs):\n",
    "            for X_batch, y_batch,lendata in train_dl:\n",
    "                y_batch = torch.tensor(y_batch,dtype=torch.float)\n",
    "                X_batch = X_batch.unsqueeze(1).float()\n",
    "\n",
    "                optimizer.zero_grad() \n",
    "                outputs = model(X_batch)\n",
    "                outputs = torch.tensor(outputs,dtype=torch.float)\n",
    "\n",
    "                train_separate_loss = [loss_function(soft(o[0:i]),yb[0:i]) for o,yb,i in zip(outputs,y_batch,lendata)]\n",
    "                train_separate_loss = np.median(train_separate_loss)\n",
    "\n",
    "                train_separate_loss = torch.tensor(train_separate_loss).requires_grad_(True)\n",
    "                train_separate_loss.backward()\n",
    "                optimizer.step()\n",
    "                print('Epoch: %d/%d, Train loss: %.6f' %(epoch+1, num_epochs, train_separate_loss.item()))\n",
    "\n",
    "train(model,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        #   # test accuracy 계산\n",
    "        #     total = 0\n",
    "        #     correct = 0\n",
    "        #     accuracy = []\n",
    "        #     for i, data in enumerate(test_dataloader, 0):\n",
    "        #     inputs, labels = data\n",
    "        #     inputs = inputs.to(device)\n",
    "        #     labels = labels.to(device)\n",
    "\n",
    "        #     # 결과값 연산\n",
    "            # outputs = model(inputs)\n",
    "\n",
    "            # _, predicted = torch.max(outputs.data, 1)\n",
    "            # total += labels.size(0)\n",
    "            # correct += (predicted == labels).sum().item()\n",
    "            # test_loss = loss_function(outputs, labels).item()\n",
    "            # accuracy.append(100 * correct/total)\n",
    "\n",
    "            # 학습 결과 출력\n",
    "            # print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f' %(epoch+1, num_epochs, train_loss.item(), test_loss, 100*correct/total))\n",
    "            # print('Epoch: %d/%d, Train loss: %.6f' %(epoch+1, num_epochs, train_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('sklearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ca674affdede15e4a6394b48f5e33f7f932c70ec65fc4d25734b56c029e94fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

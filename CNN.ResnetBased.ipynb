{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    r\"\"\"\n",
    "    3x3 convolution with padding\n",
    "    - in_planes: in_channels\n",
    "    - out_channels: out_channels\n",
    "    - bias=False: BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        r\"\"\"\n",
    "         - inplanes: input channel size\n",
    "         - planes: output channel size\n",
    "         - groups, base_width: ResNext나 Wide ResNet의 경우 사용\n",
    "        \"\"\"\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "            \n",
    "        # Basic Block의 구조\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)  # conv1에서 downsample\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # short connection\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            \n",
    "        # identity mapping시 identity mapping후 ReLU를 적용합니다.\n",
    "        # 그 이유는, ReLU를 통과하면 양의 값만 남기 때문에 Residual의 의미가 제대로 유지되지 않기 때문입니다.\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=30, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        # default values\n",
    "        self.inplanes = 1 # input feature map\n",
    "        self.dilation = 1\n",
    "        # stride를 dilation으로 대체할지 선택\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        \n",
    "        r\"\"\"\n",
    "        - 처음 입력에 적용되는 self.conv1과 self.bn1, self.relu는 모든 ResNet에서 동일 \n",
    "        - 3: 입력으로 RGB 이미지를 사용하기 때문에 convolution layer에 들어오는 input의 channel 수는 3\n",
    "        \"\"\"\n",
    "        # self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.conv1 = nn.Conv2d(1, self.inplanes, kernel_size=4, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        r\"\"\"\n",
    "        - 아래부터 block 형태와 갯수가 ResNet층마다 변화\n",
    "        - self.layer1 ~ 4: 필터의 개수는 각 block들을 거치면서 증가(64->128->256->512)\n",
    "        - self.avgpool: 모든 block을 거친 후에는 Adaptive AvgPool2d를 적용하여 (n, 512, 1, 1)의 텐서로\n",
    "        - self.fc: 이후 fc layer를 연결\n",
    "        \"\"\"\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, # 여기서부터 downsampling적용\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.layer5 = self._make_layer(block, 1024, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.layer6 = self._make_layer(block, 2048, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.drop = nn.Dropout2d()\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "\n",
    "    def _lazy_linear(out_features):\n",
    "        super(nn.LazyLinear).__init__()\n",
    "        lazy = nn.LazyLinear(out_features=out_features)\n",
    "        return(lazy)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        r\"\"\"\n",
    "        convolution layer 생성 함수\n",
    "        - block: block종류 지정\n",
    "        - planes: feature map size (input shape)\n",
    "        - blocks: layers[0]와 같이, 해당 블록이 몇개 생성돼야하는지, 블록의 갯수 (layer 반복해서 쌓는 개수)\n",
    "        - stride와 dilate은 고정\n",
    "        \"\"\"\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        \n",
    "        # the number of filters is doubled: self.inplanes와 planes 사이즈를 맞춰주기 위한 projection shortcut\n",
    "        # the feature map size is halved: stride=2로 downsampling\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        # 블록 내 시작 layer, downsampling 필요\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion # inplanes 업데이트\n",
    "        # 동일 블록 반복\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "\n",
    "        aa_len = x.shape[2]\n",
    "        lazy1 = nn.LazyLinear(30)\n",
    "        lazy2 = nn.LazyLinear(aa_len)\n",
    "\n",
    "\n",
    "        print('OG');print(x.shape)        \n",
    "        x = self.conv1(x)\n",
    "        print('After Conv2D'); print(x.shape)        \n",
    "        x = self.bn1(x)\n",
    "        print('After BN');print(x.shape)        \n",
    "        x = self.relu(x)\n",
    "        print('After ReLU');print(x.shape)        \n",
    "\n",
    "        x = self.layer1(x)\n",
    "        print('After Layer1');print(x.shape)        \n",
    "        x = self.layer2(x)\n",
    "\n",
    "        print('After Layer2');print(x.shape)        \n",
    "        x = self.layer3(x)\n",
    "\n",
    "        print('After Layer3');print(x.shape)        \n",
    "        x = self.layer4(x)\n",
    "        print('After Layer4');print(x.shape)        \n",
    "\n",
    "        x = F.avg_pool2d(x,2)\n",
    "\n",
    "        print('After Avgpool');print(x.shape)        \n",
    "\n",
    "        x = torch.squeeze(x,-1)\n",
    "        print('After Squeeze');print(x.shape)        \n",
    "\n",
    "        x = lazy1(x)\n",
    "        print('After Lazy1');print(x.shape)        \n",
    "        x = x.permute(0,2,1)\n",
    "        \n",
    "        x = lazy2(x)\n",
    "        print('After Lazy2');print(x.shape)        \n",
    "        \n",
    "        x = self.drop(x)\n",
    "        print('After Drop');print(x.shape)        \n",
    "\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        print('Final');print(x.shape)        \n",
    "\n",
    "        # x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSSMDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,pssm_in,label_in):\n",
    "        self.pssm_lst = sorted(os.listdir(pssm_in))\n",
    "        self.pssm_files = [pssm_in+f for f in self.pssm_lst]\n",
    "        self.label_files = [label_in+f.split('.')[0]+'.label.txt' for f in self.pssm_lst]\n",
    "    def __len__(self):\n",
    "        return len(self.label_files)\n",
    "    def __getitem__(self, idx):\n",
    "        self.pssm_tensor = torch.tensor(pd.read_table(self.pssm_files[idx],index_col=0).astype(float).values)\n",
    "        self.label_tensor = torch.tensor(list(map(int,open(self.label_files[idx],'r').readlines()[0].split(','))))\n",
    "        return self.pssm_tensor, self.label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    len_data = [len(item[0]) for item in batch]\n",
    "\n",
    "    target = [item[1] for item in batch]\n",
    "    dim_data = [d.size()[0] for d in data]\n",
    "    max_seqlen = max(dim_data)\n",
    "    data_transformed = [F.pad(d.T,(0,int(max_seqlen - d.size()[0])),'constant',0.0).T if d.size()[0]!=max_seqlen else d for d in data]\n",
    "    target_transformed = [F.pad(d,(0,int(max_seqlen - d.size()[0])),'constant',0.0) if d.size()[0]!=max_seqlen else d for d in target]\n",
    "    target_onehot = [torch.nn.functional.one_hot(t,num_classes = 30) for t in target_transformed]\n",
    "    \n",
    "    data_transformed = torch.nn.utils.rnn.pad_sequence(data_transformed,batch_first=True)\n",
    "    target_result = torch.nn.utils.rnn.pad_sequence(target_onehot,batch_first=True)\n",
    "    return [data_transformed, target_result,len_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "pssminpath = '/Users/suhancho/data/Uniprot_metalbinding_challenge/processed_pssm/'\n",
    "labelinpath = '/Users/suhancho/data/Uniprot_metalbinding_challenge/processed_label/'\n",
    "train_ds = PSSMDataset(pssminpath,labelinpath)\n",
    "train_dl = DataLoader(train_ds,batch_size = batch_size,shuffle = True,collate_fn=my_collate)\n",
    "model = ResNet(BasicBlock,[2,2,2,2])\n",
    "\n",
    "from torch import optim\n",
    "device = 'cpu'\n",
    "\n",
    "lr = 1e-01\n",
    "num_epochs = 5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "loss_function = nn.CrossEntropyLoss().to(device)\n",
    "loss_function = nn.MSELoss()\n",
    "params = {\n",
    "    'num_epochs':num_epochs,\n",
    "    'optimizer':optimizer,\n",
    "    'loss_function':loss_function,\n",
    "    'device':device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pseudo-lab.github.io/pytorch-guide/docs/ch04-1.html\n",
    "from torch import softmax\n",
    "soft = nn.Softmax(dim=1)\n",
    "\n",
    "def train(model, params):\n",
    "    loss_function=params[\"loss_function\"]\n",
    "    device=params[\"device\"]\n",
    "\n",
    "    for epoch in range(0, num_epochs):\n",
    "        for X_batch, y_batch,lendata in train_dl:\n",
    "            y_batch = torch.tensor(y_batch,dtype=torch.float)\n",
    "            X_batch = X_batch.unsqueeze(1).float()\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            outputs = model(X_batch)\n",
    "            outputs = torch.tensor(outputs,dtype=torch.float)\n",
    "\n",
    "            train_separate_loss = [loss_function(soft(o[0:i]),yb[0:i]) for o,yb,i in zip(outputs,y_batch,lendata)]\n",
    "            train_separate_loss = np.median(train_separate_loss)\n",
    "\n",
    "            train_separate_loss = torch.tensor(train_separate_loss)\n",
    "\n",
    "            train_separate_loss.requires_grad_(True)\n",
    "            train_separate_loss.backward()\n",
    "            optimizer.step()\n",
    "            print('Epoch: %d/%d, Train loss: %.6f' %(epoch+1, num_epochs, train_separate_loss.item()))\n",
    "\n",
    "\n",
    "            # train_loss = loss_function(outputs, y_batch)\n",
    "            # train_loss.requires_grad_(True)\n",
    "            # train_loss.backward()\n",
    "            # optimizer.step()\n",
    "            # print(train_loss)\n",
    "\n",
    "    #   # test accuracy 계산\n",
    "    #     total = 0\n",
    "    #     correct = 0\n",
    "    #     accuracy = []\n",
    "    #     for i, data in enumerate(test_dataloader, 0):\n",
    "    #     inputs, labels = data\n",
    "    #     inputs = inputs.to(device)\n",
    "    #     labels = labels.to(device)\n",
    "\n",
    "    #     # 결과값 연산\n",
    "        # outputs = model(inputs)\n",
    "\n",
    "        # _, predicted = torch.max(outputs.data, 1)\n",
    "        # total += labels.size(0)\n",
    "        # correct += (predicted == labels).sum().item()\n",
    "        # test_loss = loss_function(outputs, labels).item()\n",
    "        # accuracy.append(100 * correct/total)\n",
    "\n",
    "        # 학습 결과 출력\n",
    "        # print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f' %(epoch+1, num_epochs, train_loss.item(), test_loss, 100*correct/total))\n",
    "        # print('Epoch: %d/%d, Train loss: %.6f' %(epoch+1, num_epochs, train_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OG\n",
      "torch.Size([16, 1, 1756, 32])\n",
      "After Conv2D\n",
      "torch.Size([16, 1, 880, 18])\n",
      "After BN\n",
      "torch.Size([16, 1, 880, 18])\n",
      "After ReLU\n",
      "torch.Size([16, 1, 880, 18])\n",
      "After Layer1\n",
      "torch.Size([16, 64, 880, 18])\n",
      "After Layer2\n",
      "torch.Size([16, 128, 440, 9])\n",
      "After Layer3\n",
      "torch.Size([16, 256, 220, 5])\n",
      "After Layer4\n",
      "torch.Size([16, 512, 110, 3])\n",
      "After Avgpool\n",
      "torch.Size([16, 512, 55, 1])\n",
      "After Squeeze\n",
      "torch.Size([16, 512, 55])\n",
      "After Lazy1\n",
      "torch.Size([16, 512, 30])\n",
      "After Lazy2\n",
      "torch.Size([16, 30, 1756])\n",
      "After Drop\n",
      "torch.Size([16, 30, 1756])\n",
      "Final\n",
      "torch.Size([16, 1756, 30])\n",
      "Epoch: 1/5, Train loss: 0.032536\n",
      "OG\n",
      "torch.Size([16, 1, 835, 32])\n",
      "After Conv2D\n",
      "torch.Size([16, 1, 419, 18])\n",
      "After BN\n",
      "torch.Size([16, 1, 419, 18])\n",
      "After ReLU\n",
      "torch.Size([16, 1, 419, 18])\n",
      "After Layer1\n",
      "torch.Size([16, 64, 419, 18])\n",
      "After Layer2\n",
      "torch.Size([16, 128, 210, 9])\n",
      "After Layer3\n",
      "torch.Size([16, 256, 105, 5])\n",
      "After Layer4\n",
      "torch.Size([16, 512, 53, 3])\n",
      "After Avgpool\n",
      "torch.Size([16, 512, 26, 1])\n",
      "After Squeeze\n",
      "torch.Size([16, 512, 26])\n",
      "After Lazy1\n",
      "torch.Size([16, 512, 30])\n",
      "After Lazy2\n",
      "torch.Size([16, 30, 835])\n",
      "After Drop\n",
      "torch.Size([16, 30, 835])\n",
      "Final\n",
      "torch.Size([16, 835, 30])\n",
      "Epoch: 1/5, Train loss: 0.032531\n",
      "OG\n",
      "torch.Size([16, 1, 1344, 32])\n",
      "After Conv2D\n",
      "torch.Size([16, 1, 674, 18])\n",
      "After BN\n",
      "torch.Size([16, 1, 674, 18])\n",
      "After ReLU\n",
      "torch.Size([16, 1, 674, 18])\n",
      "After Layer1\n",
      "torch.Size([16, 64, 674, 18])\n",
      "After Layer2\n",
      "torch.Size([16, 128, 337, 9])\n",
      "After Layer3\n",
      "torch.Size([16, 256, 169, 5])\n",
      "After Layer4\n",
      "torch.Size([16, 512, 85, 3])\n",
      "After Avgpool\n",
      "torch.Size([16, 512, 42, 1])\n",
      "After Squeeze\n",
      "torch.Size([16, 512, 42])\n",
      "After Lazy1\n",
      "torch.Size([16, 512, 30])\n",
      "After Lazy2\n",
      "torch.Size([16, 30, 1344])\n",
      "After Drop\n",
      "torch.Size([16, 30, 1344])\n",
      "Final\n",
      "torch.Size([16, 1344, 30])\n",
      "Epoch: 1/5, Train loss: 0.032824\n",
      "OG\n",
      "torch.Size([16, 1, 938, 32])\n",
      "After Conv2D\n",
      "torch.Size([16, 1, 471, 18])\n",
      "After BN\n",
      "torch.Size([16, 1, 471, 18])\n",
      "After ReLU\n",
      "torch.Size([16, 1, 471, 18])\n",
      "After Layer1\n",
      "torch.Size([16, 64, 471, 18])\n",
      "After Layer2\n",
      "torch.Size([16, 128, 236, 9])\n",
      "After Layer3\n",
      "torch.Size([16, 256, 118, 5])\n",
      "After Layer4\n",
      "torch.Size([16, 512, 59, 3])\n",
      "After Avgpool\n",
      "torch.Size([16, 512, 29, 1])\n",
      "After Squeeze\n",
      "torch.Size([16, 512, 29])\n",
      "After Lazy1\n",
      "torch.Size([16, 512, 30])\n",
      "After Lazy2\n",
      "torch.Size([16, 30, 938])\n",
      "After Drop\n",
      "torch.Size([16, 30, 938])\n",
      "Final\n",
      "torch.Size([16, 938, 30])\n",
      "Epoch: 1/5, Train loss: 0.032502\n",
      "OG\n",
      "torch.Size([16, 1, 1058, 32])\n",
      "After Conv2D\n",
      "torch.Size([16, 1, 531, 18])\n",
      "After BN\n",
      "torch.Size([16, 1, 531, 18])\n",
      "After ReLU\n",
      "torch.Size([16, 1, 531, 18])\n",
      "After Layer1\n",
      "torch.Size([16, 64, 531, 18])\n",
      "After Layer2\n",
      "torch.Size([16, 128, 266, 9])\n",
      "After Layer3\n",
      "torch.Size([16, 256, 133, 5])\n",
      "After Layer4\n",
      "torch.Size([16, 512, 67, 3])\n",
      "After Avgpool\n",
      "torch.Size([16, 512, 33, 1])\n",
      "After Squeeze\n",
      "torch.Size([16, 512, 33])\n",
      "After Lazy1\n",
      "torch.Size([16, 512, 30])\n",
      "After Lazy2\n",
      "torch.Size([16, 30, 1058])\n",
      "After Drop\n",
      "torch.Size([16, 30, 1058])\n",
      "Final\n",
      "torch.Size([16, 1058, 30])\n",
      "Epoch: 1/5, Train loss: 0.032396\n",
      "OG\n",
      "torch.Size([16, 1, 764, 32])\n",
      "After Conv2D\n",
      "torch.Size([16, 1, 384, 18])\n",
      "After BN\n",
      "torch.Size([16, 1, 384, 18])\n",
      "After ReLU\n",
      "torch.Size([16, 1, 384, 18])\n",
      "After Layer1\n",
      "torch.Size([16, 64, 384, 18])\n",
      "After Layer2\n",
      "torch.Size([16, 128, 192, 9])\n",
      "After Layer3\n",
      "torch.Size([16, 256, 96, 5])\n",
      "After Layer4\n",
      "torch.Size([16, 512, 48, 3])\n",
      "After Avgpool\n",
      "torch.Size([16, 512, 24, 1])\n",
      "After Squeeze\n",
      "torch.Size([16, 512, 24])\n",
      "After Lazy1\n",
      "torch.Size([16, 512, 30])\n",
      "After Lazy2\n",
      "torch.Size([16, 30, 764])\n",
      "After Drop\n",
      "torch.Size([16, 30, 764])\n",
      "Final\n",
      "torch.Size([16, 764, 30])\n",
      "Epoch: 1/5, Train loss: 0.032515\n",
      "OG\n",
      "torch.Size([16, 1, 1390, 32])\n",
      "After Conv2D\n",
      "torch.Size([16, 1, 697, 18])\n",
      "After BN\n",
      "torch.Size([16, 1, 697, 18])\n",
      "After ReLU\n",
      "torch.Size([16, 1, 697, 18])\n",
      "After Layer1\n",
      "torch.Size([16, 64, 697, 18])\n",
      "After Layer2\n",
      "torch.Size([16, 128, 349, 9])\n",
      "After Layer3\n",
      "torch.Size([16, 256, 175, 5])\n",
      "After Layer4\n",
      "torch.Size([16, 512, 88, 3])\n",
      "After Avgpool\n",
      "torch.Size([16, 512, 44, 1])\n",
      "After Squeeze\n",
      "torch.Size([16, 512, 44])\n",
      "After Lazy1\n",
      "torch.Size([16, 512, 30])\n",
      "After Lazy2\n",
      "torch.Size([16, 30, 1390])\n",
      "After Drop\n",
      "torch.Size([16, 30, 1390])\n",
      "Final\n",
      "torch.Size([16, 1390, 30])\n",
      "Epoch: 1/5, Train loss: 0.032575\n",
      "OG\n",
      "torch.Size([16, 1, 1448, 32])\n",
      "After Conv2D\n",
      "torch.Size([16, 1, 726, 18])\n",
      "After BN\n",
      "torch.Size([16, 1, 726, 18])\n",
      "After ReLU\n",
      "torch.Size([16, 1, 726, 18])\n",
      "After Layer1\n",
      "torch.Size([16, 64, 726, 18])\n",
      "After Layer2\n",
      "torch.Size([16, 128, 363, 9])\n",
      "After Layer3\n",
      "torch.Size([16, 256, 182, 5])\n",
      "After Layer4\n",
      "torch.Size([16, 512, 91, 3])\n",
      "After Avgpool\n",
      "torch.Size([16, 512, 45, 1])\n",
      "After Squeeze\n",
      "torch.Size([16, 512, 45])\n",
      "After Lazy1\n",
      "torch.Size([16, 512, 30])\n",
      "After Lazy2\n",
      "torch.Size([16, 30, 1448])\n",
      "After Drop\n",
      "torch.Size([16, 30, 1448])\n",
      "Final\n",
      "torch.Size([16, 1448, 30])\n",
      "Epoch: 1/5, Train loss: 0.032328\n",
      "OG\n",
      "torch.Size([16, 1, 977, 32])\n",
      "After Conv2D\n",
      "torch.Size([16, 1, 490, 18])\n",
      "After BN\n",
      "torch.Size([16, 1, 490, 18])\n",
      "After ReLU\n",
      "torch.Size([16, 1, 490, 18])\n",
      "After Layer1\n",
      "torch.Size([16, 64, 490, 18])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [264], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [263], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, params)\u001b[0m\n\u001b[1;32m     12\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m X_batch\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad() \n\u001b[0;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(outputs,dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     18\u001b[0m train_separate_loss \u001b[38;5;241m=\u001b[39m [loss_function(soft(o[\u001b[38;5;241m0\u001b[39m:i]),yb[\u001b[38;5;241m0\u001b[39m:i]) \u001b[38;5;28;01mfor\u001b[39;00m o,yb,i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(outputs,y_batch,lendata)]\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [259], line 165\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [259], line 128\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    126\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAfter Layer1\u001b[39m\u001b[38;5;124m'\u001b[39m);\u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)        \n\u001b[0;32m--> 128\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAfter Layer2\u001b[39m\u001b[38;5;124m'\u001b[39m);\u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)        \n\u001b[1;32m    131\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [34], line 34\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     32\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m---> 34\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# short connection\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9d86feb0499a0b58932a2305ba04f997e477cb03dd1b79441914e4f34b762fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
